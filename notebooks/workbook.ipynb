{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9111fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m617.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:09\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m889.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845499 sha256=3313a140c6cac7c68491535354b13f37d0fbe34535d71805278c46951edc3d45\n",
      "  Stored in directory: /home/sharpnel/.cache/pip/wheels/51/c8/18/298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547be0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import lit, desc, col, size, array_contains\\\n",
    ", isnan, udf, hour, array_min, array_max, countDistinct\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff907c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/24 23:36:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"carCrash\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6cba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseSchema = StructType([\n",
    "    StructField(\"Date\", DateType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Total\", FloatType(), True),\n",
    "    StructField(\"Payment\", StringType(), True),\n",
    "])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aa3631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:=====>                                                    (1 + 9) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/24 23:36:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+--------+--------+--------+------------+------------------+-----------------+--------+-----------------+------------+------------+-------------------+-----------------+--------------+-----------+---------------------+----------------+------------------+---------------------+----------------+-----------------+---------------+---------------+------------------+--------------+-------------+--------------+-------------+---------+--------------------+-----------------+------------------+--------+\n",
      "|CRASH_ID|UNIT_NBR|PRSN_NBR|PRSN_TYPE_ID|PRSN_OCCPNT_POS_ID|PRSN_INJRY_SEV_ID|PRSN_AGE|PRSN_ETHNICITY_ID|PRSN_GNDR_ID|PRSN_EJCT_ID|       PRSN_REST_ID|   PRSN_AIRBAG_ID|PRSN_HELMET_ID|PRSN_SOL_FL|PRSN_ALC_SPEC_TYPE_ID|PRSN_ALC_RSLT_ID|PRSN_BAC_TEST_RSLT|PRSN_DRG_SPEC_TYPE_ID|PRSN_DRG_RSLT_ID|DRVR_DRG_CAT_1_ID|PRSN_DEATH_TIME|INCAP_INJRY_CNT|NONINCAP_INJRY_CNT|POSS_INJRY_CNT|NON_INJRY_CNT|UNKN_INJRY_CNT|TOT_INJRY_CNT|DEATH_CNT|    DRVR_LIC_TYPE_ID|DRVR_LIC_STATE_ID|   DRVR_LIC_CLS_ID|DRVR_ZIP|\n",
      "+--------+--------+--------+------------+------------------+-----------------+--------+-----------------+------------+------------+-------------------+-----------------+--------------+-----------+---------------------+----------------+------------------+---------------------+----------------+-----------------+---------------+---------------+------------------+--------------+-------------+--------------+-------------+---------+--------------------+-----------------+------------------+--------+\n",
      "|14768622|       1|       1|      DRIVER|        FRONT LEFT|      NOT INJURED|      27|         HISPANIC|        MALE|          NO|               NONE|DEPLOYED MULTIPLE|NOT APPLICABLE|          N|                BLOOD|        Positive|             0.225|                 NONE|  NOT APPLICABLE|   NOT APPLICABLE|           null|              0|                 0|             0|            1|             0|            0|        0|      DRIVER LICENSE|            Texas|           CLASS C|   77357|\n",
      "|14838637|       1|       1|      DRIVER|        FRONT LEFT|      NOT INJURED|      31|            WHITE|        MALE|          NO|SHOULDER & LAP BELT|     NOT DEPLOYED|NOT APPLICABLE|          N|               BREATH|        Positive|              0.21|                 NONE|  NOT APPLICABLE|   NOT APPLICABLE|           null|              0|                 0|             0|            1|             0|            0|        0|      DRIVER LICENSE|         New York|OTHER/OUT OF STATE|   13830|\n",
      "|14838637|       2|       1|      DRIVER|        FRONT LEFT|      NOT INJURED|      41|            BLACK|        MALE|          NO|SHOULDER & LAP BELT|     NOT DEPLOYED|NOT APPLICABLE|          N|                 NONE|              NA|                NA|                 NONE|  NOT APPLICABLE|   NOT APPLICABLE|           null|              0|                 0|             0|            1|             0|            0|        0|COMMERCIAL DRIVER...|            Texas|           CLASS A|   78934|\n",
      "+--------+--------+--------+------------+------------------+-----------------+--------+-----------------+------------+------------+-------------------+-----------------+--------------+-----------+---------------------+----------------+------------------+---------------------+----------------+-----------------+---------------+---------------+------------------+--------------+-------------+--------------+-------------+---------+--------------------+-----------------+------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "purchaseDataframe = spark.read.csv(\n",
    "    \"../resources/raw/Primary_Person_use.csv\", \n",
    "    header=True, inferSchema=True, sep=\",\")\n",
    "#show 3 rows of our DataFrame\n",
    "print(purchaseDataframe.show(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ab5ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  156954\n"
     ]
    }
   ],
   "source": [
    "num_rows = purchaseDataframe.count()\n",
    "print(\"number of rows: \", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e078ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_killed_df = purchaseDataframe.filter(\"PRSN_GNDR_ID =='MALE' and  DEATH_CNT==1\").select('CRASH_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2f1eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_killed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e9f581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRSN_GNDR_ID</th>\n",
       "      <th>DEATH_CNT</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MALE</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRSN_GNDR_ID  DEATH_CNT  count\n",
       "0         MALE          1    180\n",
       "1       FEMALE          1     64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseDataframe.select('CRASH_ID','PRSN_GNDR_ID','DEATH_CNT').distinct().groupBy(\"PRSN_GNDR_ID\",\"DEATH_CNT\").count().alias(\"Death Count\").where(\"DEATH_CNT==1\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a491ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('CRASH_ID', IntegerType(), True), StructField('UNIT_NBR', IntegerType(), True), StructField('PRSN_NBR', IntegerType(), True), StructField('PRSN_TYPE_ID', StringType(), True), StructField('PRSN_OCCPNT_POS_ID', StringType(), True), StructField('PRSN_INJRY_SEV_ID', StringType(), True), StructField('PRSN_AGE', StringType(), True), StructField('PRSN_ETHNICITY_ID', StringType(), True), StructField('PRSN_GNDR_ID', StringType(), True), StructField('PRSN_EJCT_ID', StringType(), True), StructField('PRSN_REST_ID', StringType(), True), StructField('PRSN_AIRBAG_ID', StringType(), True), StructField('PRSN_HELMET_ID', StringType(), True), StructField('PRSN_SOL_FL', StringType(), True), StructField('PRSN_ALC_SPEC_TYPE_ID', StringType(), True), StructField('PRSN_ALC_RSLT_ID', StringType(), True), StructField('PRSN_BAC_TEST_RSLT', StringType(), True), StructField('PRSN_DRG_SPEC_TYPE_ID', StringType(), True), StructField('PRSN_DRG_RSLT_ID', StringType(), True), StructField('DRVR_DRG_CAT_1_ID', StringType(), True), StructField('PRSN_DEATH_TIME', TimestampType(), True), StructField('INCAP_INJRY_CNT', IntegerType(), True), StructField('NONINCAP_INJRY_CNT', IntegerType(), True), StructField('POSS_INJRY_CNT', IntegerType(), True), StructField('NON_INJRY_CNT', IntegerType(), True), StructField('UNKN_INJRY_CNT', IntegerType(), True), StructField('TOT_INJRY_CNT', IntegerType(), True), StructField('DEATH_CNT', IntegerType(), True), StructField('DRVR_LIC_TYPE_ID', StringType(), True), StructField('DRVR_LIC_STATE_ID', StringType(), True), StructField('DRVR_LIC_CLS_ID', StringType(), True), StructField('DRVR_ZIP', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseDataframe.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c660bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567b4169",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'isnan(PRSN_DEATH_TIME)' due to data type mismatch: argument 1 requires (double or float) type, however, 'PRSN_DEATH_TIME' is of timestamp type.;\n'Aggregate [count(CASE WHEN (isnan(cast(CRASH_ID#17 as double)) OR isnull(CRASH_ID#17)) THEN CRASH_ID END) AS CRASH_ID#403L, count(CASE WHEN (isnan(cast(UNIT_NBR#18 as double)) OR isnull(UNIT_NBR#18)) THEN UNIT_NBR END) AS UNIT_NBR#405L, count(CASE WHEN (isnan(cast(PRSN_NBR#19 as double)) OR isnull(PRSN_NBR#19)) THEN PRSN_NBR END) AS PRSN_NBR#407L, count(CASE WHEN (isnan(cast(PRSN_TYPE_ID#20 as double)) OR isnull(PRSN_TYPE_ID#20)) THEN PRSN_TYPE_ID END) AS PRSN_TYPE_ID#409L, count(CASE WHEN (isnan(cast(PRSN_OCCPNT_POS_ID#21 as double)) OR isnull(PRSN_OCCPNT_POS_ID#21)) THEN PRSN_OCCPNT_POS_ID END) AS PRSN_OCCPNT_POS_ID#411L, count(CASE WHEN (isnan(cast(PRSN_INJRY_SEV_ID#22 as double)) OR isnull(PRSN_INJRY_SEV_ID#22)) THEN PRSN_INJRY_SEV_ID END) AS PRSN_INJRY_SEV_ID#413L, count(CASE WHEN (isnan(cast(PRSN_AGE#23 as double)) OR isnull(PRSN_AGE#23)) THEN PRSN_AGE END) AS PRSN_AGE#415L, count(CASE WHEN (isnan(cast(PRSN_ETHNICITY_ID#24 as double)) OR isnull(PRSN_ETHNICITY_ID#24)) THEN PRSN_ETHNICITY_ID END) AS PRSN_ETHNICITY_ID#417L, count(CASE WHEN (isnan(cast(PRSN_GNDR_ID#25 as double)) OR isnull(PRSN_GNDR_ID#25)) THEN PRSN_GNDR_ID END) AS PRSN_GNDR_ID#419L, count(CASE WHEN (isnan(cast(PRSN_EJCT_ID#26 as double)) OR isnull(PRSN_EJCT_ID#26)) THEN PRSN_EJCT_ID END) AS PRSN_EJCT_ID#421L, count(CASE WHEN (isnan(cast(PRSN_REST_ID#27 as double)) OR isnull(PRSN_REST_ID#27)) THEN PRSN_REST_ID END) AS PRSN_REST_ID#423L, count(CASE WHEN (isnan(cast(PRSN_AIRBAG_ID#28 as double)) OR isnull(PRSN_AIRBAG_ID#28)) THEN PRSN_AIRBAG_ID END) AS PRSN_AIRBAG_ID#425L, count(CASE WHEN (isnan(cast(PRSN_HELMET_ID#29 as double)) OR isnull(PRSN_HELMET_ID#29)) THEN PRSN_HELMET_ID END) AS PRSN_HELMET_ID#427L, count(CASE WHEN (isnan(cast(PRSN_SOL_FL#30 as double)) OR isnull(PRSN_SOL_FL#30)) THEN PRSN_SOL_FL END) AS PRSN_SOL_FL#429L, count(CASE WHEN (isnan(cast(PRSN_ALC_SPEC_TYPE_ID#31 as double)) OR isnull(PRSN_ALC_SPEC_TYPE_ID#31)) THEN PRSN_ALC_SPEC_TYPE_ID END) AS PRSN_ALC_SPEC_TYPE_ID#431L, count(CASE WHEN (isnan(cast(PRSN_ALC_RSLT_ID#32 as double)) OR isnull(PRSN_ALC_RSLT_ID#32)) THEN PRSN_ALC_RSLT_ID END) AS PRSN_ALC_RSLT_ID#433L, count(CASE WHEN (isnan(cast(PRSN_BAC_TEST_RSLT#33 as double)) OR isnull(PRSN_BAC_TEST_RSLT#33)) THEN PRSN_BAC_TEST_RSLT END) AS PRSN_BAC_TEST_RSLT#435L, count(CASE WHEN (isnan(cast(PRSN_DRG_SPEC_TYPE_ID#34 as double)) OR isnull(PRSN_DRG_SPEC_TYPE_ID#34)) THEN PRSN_DRG_SPEC_TYPE_ID END) AS PRSN_DRG_SPEC_TYPE_ID#437L, count(CASE WHEN (isnan(cast(PRSN_DRG_RSLT_ID#35 as double)) OR isnull(PRSN_DRG_RSLT_ID#35)) THEN PRSN_DRG_RSLT_ID END) AS PRSN_DRG_RSLT_ID#439L, count(CASE WHEN (isnan(cast(DRVR_DRG_CAT_1_ID#36 as double)) OR isnull(DRVR_DRG_CAT_1_ID#36)) THEN DRVR_DRG_CAT_1_ID END) AS DRVR_DRG_CAT_1_ID#441L, count(CASE WHEN (isnan(PRSN_DEATH_TIME#37) OR isnull(PRSN_DEATH_TIME#37)) THEN PRSN_DEATH_TIME END) AS PRSN_DEATH_TIME#443, count(CASE WHEN (isnan(cast(INCAP_INJRY_CNT#38 as double)) OR isnull(INCAP_INJRY_CNT#38)) THEN INCAP_INJRY_CNT END) AS INCAP_INJRY_CNT#445L, count(CASE WHEN (isnan(cast(NONINCAP_INJRY_CNT#39 as double)) OR isnull(NONINCAP_INJRY_CNT#39)) THEN NONINCAP_INJRY_CNT END) AS NONINCAP_INJRY_CNT#447L, count(CASE WHEN (isnan(cast(POSS_INJRY_CNT#40 as double)) OR isnull(POSS_INJRY_CNT#40)) THEN POSS_INJRY_CNT END) AS POSS_INJRY_CNT#449L, ... 8 more fields]\n+- Relation [CRASH_ID#17,UNIT_NBR#18,PRSN_NBR#19,PRSN_TYPE_ID#20,PRSN_OCCPNT_POS_ID#21,PRSN_INJRY_SEV_ID#22,PRSN_AGE#23,PRSN_ETHNICITY_ID#24,PRSN_GNDR_ID#25,PRSN_EJCT_ID#26,PRSN_REST_ID#27,PRSN_AIRBAG_ID#28,PRSN_HELMET_ID#29,PRSN_SOL_FL#30,PRSN_ALC_SPEC_TYPE_ID#31,PRSN_ALC_RSLT_ID#32,PRSN_BAC_TEST_RSLT#33,PRSN_DRG_SPEC_TYPE_ID#34,PRSN_DRG_RSLT_ID#35,DRVR_DRG_CAT_1_ID#36,PRSN_DEATH_TIME#37,INCAP_INJRY_CNT#38,NONINCAP_INJRY_CNT#39,POSS_INJRY_CNT#40,... 8 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19221/2301768897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m purchaseDataframe.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in purchaseDataframe.columns]\n\u001b[0m\u001b[1;32m      2\u001b[0m    ).show()\n",
      "\u001b[0;32m~/spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'isnan(PRSN_DEATH_TIME)' due to data type mismatch: argument 1 requires (double or float) type, however, 'PRSN_DEATH_TIME' is of timestamp type.;\n'Aggregate [count(CASE WHEN (isnan(cast(CRASH_ID#17 as double)) OR isnull(CRASH_ID#17)) THEN CRASH_ID END) AS CRASH_ID#403L, count(CASE WHEN (isnan(cast(UNIT_NBR#18 as double)) OR isnull(UNIT_NBR#18)) THEN UNIT_NBR END) AS UNIT_NBR#405L, count(CASE WHEN (isnan(cast(PRSN_NBR#19 as double)) OR isnull(PRSN_NBR#19)) THEN PRSN_NBR END) AS PRSN_NBR#407L, count(CASE WHEN (isnan(cast(PRSN_TYPE_ID#20 as double)) OR isnull(PRSN_TYPE_ID#20)) THEN PRSN_TYPE_ID END) AS PRSN_TYPE_ID#409L, count(CASE WHEN (isnan(cast(PRSN_OCCPNT_POS_ID#21 as double)) OR isnull(PRSN_OCCPNT_POS_ID#21)) THEN PRSN_OCCPNT_POS_ID END) AS PRSN_OCCPNT_POS_ID#411L, count(CASE WHEN (isnan(cast(PRSN_INJRY_SEV_ID#22 as double)) OR isnull(PRSN_INJRY_SEV_ID#22)) THEN PRSN_INJRY_SEV_ID END) AS PRSN_INJRY_SEV_ID#413L, count(CASE WHEN (isnan(cast(PRSN_AGE#23 as double)) OR isnull(PRSN_AGE#23)) THEN PRSN_AGE END) AS PRSN_AGE#415L, count(CASE WHEN (isnan(cast(PRSN_ETHNICITY_ID#24 as double)) OR isnull(PRSN_ETHNICITY_ID#24)) THEN PRSN_ETHNICITY_ID END) AS PRSN_ETHNICITY_ID#417L, count(CASE WHEN (isnan(cast(PRSN_GNDR_ID#25 as double)) OR isnull(PRSN_GNDR_ID#25)) THEN PRSN_GNDR_ID END) AS PRSN_GNDR_ID#419L, count(CASE WHEN (isnan(cast(PRSN_EJCT_ID#26 as double)) OR isnull(PRSN_EJCT_ID#26)) THEN PRSN_EJCT_ID END) AS PRSN_EJCT_ID#421L, count(CASE WHEN (isnan(cast(PRSN_REST_ID#27 as double)) OR isnull(PRSN_REST_ID#27)) THEN PRSN_REST_ID END) AS PRSN_REST_ID#423L, count(CASE WHEN (isnan(cast(PRSN_AIRBAG_ID#28 as double)) OR isnull(PRSN_AIRBAG_ID#28)) THEN PRSN_AIRBAG_ID END) AS PRSN_AIRBAG_ID#425L, count(CASE WHEN (isnan(cast(PRSN_HELMET_ID#29 as double)) OR isnull(PRSN_HELMET_ID#29)) THEN PRSN_HELMET_ID END) AS PRSN_HELMET_ID#427L, count(CASE WHEN (isnan(cast(PRSN_SOL_FL#30 as double)) OR isnull(PRSN_SOL_FL#30)) THEN PRSN_SOL_FL END) AS PRSN_SOL_FL#429L, count(CASE WHEN (isnan(cast(PRSN_ALC_SPEC_TYPE_ID#31 as double)) OR isnull(PRSN_ALC_SPEC_TYPE_ID#31)) THEN PRSN_ALC_SPEC_TYPE_ID END) AS PRSN_ALC_SPEC_TYPE_ID#431L, count(CASE WHEN (isnan(cast(PRSN_ALC_RSLT_ID#32 as double)) OR isnull(PRSN_ALC_RSLT_ID#32)) THEN PRSN_ALC_RSLT_ID END) AS PRSN_ALC_RSLT_ID#433L, count(CASE WHEN (isnan(cast(PRSN_BAC_TEST_RSLT#33 as double)) OR isnull(PRSN_BAC_TEST_RSLT#33)) THEN PRSN_BAC_TEST_RSLT END) AS PRSN_BAC_TEST_RSLT#435L, count(CASE WHEN (isnan(cast(PRSN_DRG_SPEC_TYPE_ID#34 as double)) OR isnull(PRSN_DRG_SPEC_TYPE_ID#34)) THEN PRSN_DRG_SPEC_TYPE_ID END) AS PRSN_DRG_SPEC_TYPE_ID#437L, count(CASE WHEN (isnan(cast(PRSN_DRG_RSLT_ID#35 as double)) OR isnull(PRSN_DRG_RSLT_ID#35)) THEN PRSN_DRG_RSLT_ID END) AS PRSN_DRG_RSLT_ID#439L, count(CASE WHEN (isnan(cast(DRVR_DRG_CAT_1_ID#36 as double)) OR isnull(DRVR_DRG_CAT_1_ID#36)) THEN DRVR_DRG_CAT_1_ID END) AS DRVR_DRG_CAT_1_ID#441L, count(CASE WHEN (isnan(PRSN_DEATH_TIME#37) OR isnull(PRSN_DEATH_TIME#37)) THEN PRSN_DEATH_TIME END) AS PRSN_DEATH_TIME#443, count(CASE WHEN (isnan(cast(INCAP_INJRY_CNT#38 as double)) OR isnull(INCAP_INJRY_CNT#38)) THEN INCAP_INJRY_CNT END) AS INCAP_INJRY_CNT#445L, count(CASE WHEN (isnan(cast(NONINCAP_INJRY_CNT#39 as double)) OR isnull(NONINCAP_INJRY_CNT#39)) THEN NONINCAP_INJRY_CNT END) AS NONINCAP_INJRY_CNT#447L, count(CASE WHEN (isnan(cast(POSS_INJRY_CNT#40 as double)) OR isnull(POSS_INJRY_CNT#40)) THEN POSS_INJRY_CNT END) AS POSS_INJRY_CNT#449L, ... 8 more fields]\n+- Relation [CRASH_ID#17,UNIT_NBR#18,PRSN_NBR#19,PRSN_TYPE_ID#20,PRSN_OCCPNT_POS_ID#21,PRSN_INJRY_SEV_ID#22,PRSN_AGE#23,PRSN_ETHNICITY_ID#24,PRSN_GNDR_ID#25,PRSN_EJCT_ID#26,PRSN_REST_ID#27,PRSN_AIRBAG_ID#28,PRSN_HELMET_ID#29,PRSN_SOL_FL#30,PRSN_ALC_SPEC_TYPE_ID#31,PRSN_ALC_RSLT_ID#32,PRSN_BAC_TEST_RSLT#33,PRSN_DRG_SPEC_TYPE_ID#34,PRSN_DRG_RSLT_ID#35,DRVR_DRG_CAT_1_ID#36,PRSN_DEATH_TIME#37,INCAP_INJRY_CNT#38,NONINCAP_INJRY_CNT#39,POSS_INJRY_CNT#40,... 8 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "purchaseDataframe.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in purchaseDataframe.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e783b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
