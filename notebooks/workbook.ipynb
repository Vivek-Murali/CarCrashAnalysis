{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9111fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m617.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:09\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m889.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845499 sha256=3313a140c6cac7c68491535354b13f37d0fbe34535d71805278c46951edc3d45\n",
      "  Stored in directory: /home/sharpnel/.cache/pip/wheels/51/c8/18/298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547be0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import lit, desc, col, size, array_contains\\\n",
    ", isnan, udf, hour, array_min, array_max, countDistinct\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff907c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/24 13:54:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"carCrash\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6cba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseSchema = StructType([\n",
    "    StructField(\"Date\", DateType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Total\", FloatType(), True),\n",
    "    StructField(\"Payment\", StringType(), True),\n",
    "])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6aa3631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+------------+------------------+-----------------+--------+-----------------+------------+------------+-------------------+-----------------+--------------+-----------+---------------------+----------------+------------------+---------------------+----------------+-----------------+---------------+---------------+------------------+--------------+-------------+--------------+-------------+---------+--------------------+-----------------+------------------+--------+\n",
      "|CRASH_ID|UNIT_NBR|PRSN_NBR|PRSN_TYPE_ID|PRSN_OCCPNT_POS_ID|PRSN_INJRY_SEV_ID|PRSN_AGE|PRSN_ETHNICITY_ID|PRSN_GNDR_ID|PRSN_EJCT_ID|       PRSN_REST_ID|   PRSN_AIRBAG_ID|PRSN_HELMET_ID|PRSN_SOL_FL|PRSN_ALC_SPEC_TYPE_ID|PRSN_ALC_RSLT_ID|PRSN_BAC_TEST_RSLT|PRSN_DRG_SPEC_TYPE_ID|PRSN_DRG_RSLT_ID|DRVR_DRG_CAT_1_ID|PRSN_DEATH_TIME|INCAP_INJRY_CNT|NONINCAP_INJRY_CNT|POSS_INJRY_CNT|NON_INJRY_CNT|UNKN_INJRY_CNT|TOT_INJRY_CNT|DEATH_CNT|    DRVR_LIC_TYPE_ID|DRVR_LIC_STATE_ID|   DRVR_LIC_CLS_ID|DRVR_ZIP|\n",
      "+--------+--------+--------+------------+------------------+-----------------+--------+-----------------+------------+------------+-------------------+-----------------+--------------+-----------+---------------------+----------------+------------------+---------------------+----------------+-----------------+---------------+---------------+------------------+--------------+-------------+--------------+-------------+---------+--------------------+-----------------+------------------+--------+\n",
      "|14768622|       1|       1|      DRIVER|        FRONT LEFT|      NOT INJURED|      27|         HISPANIC|        MALE|          NO|               NONE|DEPLOYED MULTIPLE|NOT APPLICABLE|          N|                BLOOD|        Positive|             0.225|                 NONE|  NOT APPLICABLE|   NOT APPLICABLE|           null|              0|                 0|             0|            1|             0|            0|        0|      DRIVER LICENSE|            Texas|           CLASS C|   77357|\n",
      "|14838637|       1|       1|      DRIVER|        FRONT LEFT|      NOT INJURED|      31|            WHITE|        MALE|          NO|SHOULDER & LAP BELT|     NOT DEPLOYED|NOT APPLICABLE|          N|               BREATH|        Positive|              0.21|                 NONE|  NOT APPLICABLE|   NOT APPLICABLE|           null|              0|                 0|             0|            1|             0|            0|        0|      DRIVER LICENSE|         New York|OTHER/OUT OF STATE|   13830|\n",
      "|14838637|       2|       1|      DRIVER|        FRONT LEFT|      NOT INJURED|      41|            BLACK|        MALE|          NO|SHOULDER & LAP BELT|     NOT DEPLOYED|NOT APPLICABLE|          N|                 NONE|              NA|                NA|                 NONE|  NOT APPLICABLE|   NOT APPLICABLE|           null|              0|                 0|             0|            1|             0|            0|        0|COMMERCIAL DRIVER...|            Texas|           CLASS A|   78934|\n",
      "+--------+--------+--------+------------+------------------+-----------------+--------+-----------------+------------+------------+-------------------+-----------------+--------------+-----------+---------------------+----------------+------------------+---------------------+----------------+-----------------+---------------+---------------+------------------+--------------+-------------+--------------+-------------+---------+--------------------+-----------------+------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "purchaseDataframe = spark.read.csv(\n",
    "    \"../resources/raw/Primary_Person_use.csv\", \n",
    "    header=True, inferSchema=True, sep=\",\")\n",
    "#show 3 rows of our DataFrame\n",
    "print(purchaseDataframe.show(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ab5ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  156954\n"
     ]
    }
   ],
   "source": [
    "num_rows = purchaseDataframe.count()\n",
    "print(\"number of rows: \", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e078ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_killed_df = purchaseDataframe.filter(\"PRSN_GNDR_ID =='MALE' and  DEATH_CNT==1\").select('CRASH_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2f1eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_killed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e9f581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRSN_GNDR_ID</th>\n",
       "      <th>DEATH_CNT</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MALE</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRSN_GNDR_ID  DEATH_CNT  count\n",
       "0         MALE          1    180\n",
       "1       FEMALE          1     64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaseDataframe.select('CRASH_ID','PRSN_GNDR_ID','DEATH_CNT').distinct().groupBy(\"PRSN_GNDR_ID\",\"DEATH_CNT\").count().alias(\"Death Count\").where(\"DEATH_CNT==1\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491ba98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
